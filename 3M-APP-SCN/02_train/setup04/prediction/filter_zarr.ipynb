{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Zarr file\n",
    "\n",
    "Only keep segmentation IDs showing up in a least K layers\n",
    "\n",
    "Parallelized for multi-core utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 366/1286 [55:11<2:18:43,  9.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m num_cores \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(cpu_count(), \u001b[39m15\u001b[39m)  \u001b[39m# Use up to 15 cores\u001b[39;00m\n\u001b[1;32m     75\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of cores: \u001b[39m\u001b[39m{\u001b[39;00mnum_cores\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m segmentation_counts \u001b[39m=\u001b[39m get_segmentation_counts_parallel(zarr_array, num_cores)\n",
      "Cell \u001b[0;32mIn[19], line 57\u001b[0m, in \u001b[0;36mget_segmentation_counts_parallel\u001b[0;34m(zarr_array, num_cores)\u001b[0m\n\u001b[1;32m     55\u001b[0m             pbar\u001b[39m.\u001b[39mupdate(current_count \u001b[39m-\u001b[39m last_count)\n\u001b[1;32m     56\u001b[0m             last_count \u001b[39m=\u001b[39m current_count\n\u001b[0;32m---> 57\u001b[0m             time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m         results \u001b[39m=\u001b[39m async_result\u001b[39m.\u001b[39mget()\n\u001b[1;32m     60\u001b[0m \u001b[39m# Combine results\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import os\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count, Manager\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='parallel_processing.log', level=logging.INFO)\n",
    "\n",
    "def count_segmentation_for_layers(args):\n",
    "  zarr_array, start_layer, end_layer, progress_bar = args\n",
    "  segmentation_counts = {}\n",
    "  for layer_index in range(start_layer, end_layer):\n",
    "    logging.info(f\"Processing layer {layer_index} in range {start_layer}-{end_layer}\")\n",
    "    layer = zarr_array[layer_index, :, :]\n",
    "    unique_segmentation_ids = np.unique(layer)\n",
    "    for seg_id in unique_segmentation_ids:\n",
    "      if seg_id != 0:\n",
    "        segmentation_counts[seg_id] = segmentation_counts.get(seg_id, 0) + 1\n",
    "    progress_bar.value += 1  # Update the shared counter directly\n",
    "  return segmentation_counts\n",
    "\n",
    "def get_segmentation_counts_parallel(zarr_array, num_cores):\n",
    "  total_layers = zarr_array.shape[0]\n",
    "  layers_per_core = total_layers // num_cores\n",
    "  remainder = total_layers % num_cores\n",
    "\n",
    "  with Manager() as manager:\n",
    "    progress_bar = manager.Value('i', 0)  # shared counter\n",
    "\n",
    "    # Distribute layers among cores\n",
    "    args = []\n",
    "    start_layer = 0\n",
    "    for i in range(num_cores):\n",
    "      end_layer = start_layer + layers_per_core\n",
    "      if i < remainder:\n",
    "        end_layer += 1  # give one extra layer to this core\n",
    "      args.append((zarr_array, start_layer, end_layer, progress_bar))\n",
    "      start_layer = end_layer\n",
    "\n",
    "    logging.info(f'Layers per core: {layers_per_core}, with {remainder} cores processing an extra layer.')\n",
    "\n",
    "    # Process in parallel\n",
    "    with Pool(num_cores) as pool:\n",
    "      async_result = pool.map_async(count_segmentation_for_layers, args)\n",
    "\n",
    "      # Update tqdm while the processes are running\n",
    "      with tqdm(total=zarr_array.shape[0], position=0, leave=True) as pbar:\n",
    "        last_count = 0\n",
    "        while not async_result.ready():\n",
    "          current_count = progress_bar.value\n",
    "          pbar.update(current_count - last_count)\n",
    "          last_count = current_count\n",
    "          time.sleep(0.5)\n",
    "        results = async_result.get()\n",
    "\n",
    "    # Combine results\n",
    "    logging.info('Combining results')\n",
    "    combined_counts = {}\n",
    "    for segmentation_counts in results:\n",
    "      for seg_id, count in segmentation_counts.items():\n",
    "        combined_counts[seg_id] = combined_counts.get(seg_id, 0) + count\n",
    "\n",
    "  logging.info(f'Total count: {len(combined_counts)}')\n",
    "  return combined_counts\n",
    "\n",
    "data = zarr.open('3M-APP-SCN.zarr', mode='r')\n",
    "zarr_array = data['segmentation_0.1']\n",
    "logging.info(f\"Zarr array shape: {zarr_array.shape}\")\n",
    "num_cores = min(cpu_count(), 15)  # Use up to 15 cores\n",
    "logging.info(f\"Number of cores: {num_cores}\")\n",
    "segmentation_counts = get_segmentation_counts_parallel(zarr_array, num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer index: 0, Current max value: 4227121\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m data \u001b[39m=\u001b[39m zarr\u001b[39m.\u001b[39mopen(\u001b[39m'\u001b[39m\u001b[39m3M-APP-SCN.zarr\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m zarr_array \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39msegmentation_0.1\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m max_value \u001b[39m=\u001b[39m find_max_value(zarr_array)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe maximum value in the entire array is: \u001b[39m\u001b[39m{\u001b[39;00mmax_value\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m, in \u001b[0;36mfind_max_value\u001b[0;34m(zarr_array)\u001b[0m\n\u001b[1;32m      3\u001b[0m total_layers \u001b[39m=\u001b[39m zarr_array\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m layer_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_layers):\n\u001b[0;32m----> 6\u001b[0m   layer \u001b[39m=\u001b[39m zarr_array[layer_index, :, :]\n\u001b[1;32m      7\u001b[0m   layer_max \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mmax()\n\u001b[1;32m      8\u001b[0m   \u001b[39mif\u001b[39;00m layer_max \u001b[39m>\u001b[39m max_value:\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/zarr/core.py:842\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    840\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvindex[selection]\n\u001b[1;32m    841\u001b[0m \u001b[39melif\u001b[39;00m is_pure_orthogonal_indexing(pure_selection, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim):\n\u001b[0;32m--> 842\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_orthogonal_selection(pure_selection, fields\u001b[39m=\u001b[39;49mfields)\n\u001b[1;32m    843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_basic_selection(pure_selection, fields\u001b[39m=\u001b[39mfields)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/zarr/core.py:1124\u001b[0m, in \u001b[0;36mArray.get_orthogonal_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39m# setup indexer\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m indexer \u001b[39m=\u001b[39m OrthogonalIndexer(selection, \u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_selection(indexer\u001b[39m=\u001b[39;49mindexer, out\u001b[39m=\u001b[39;49mout, fields\u001b[39m=\u001b[39;49mfields)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/zarr/core.py:1388\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[39mif\u001b[39;00m math\u001b[39m.\u001b[39mprod(out_shape) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1386\u001b[0m     \u001b[39m# allow storage to get multiple items at once\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mindexer)\n\u001b[0;32m-> 1388\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chunk_getitems(\n\u001b[1;32m   1389\u001b[0m         lchunk_coords,\n\u001b[1;32m   1390\u001b[0m         lchunk_selection,\n\u001b[1;32m   1391\u001b[0m         out,\n\u001b[1;32m   1392\u001b[0m         lout_selection,\n\u001b[1;32m   1393\u001b[0m         drop_axes\u001b[39m=\u001b[39;49mindexer\u001b[39m.\u001b[39;49mdrop_axes,\n\u001b[1;32m   1394\u001b[0m         fields\u001b[39m=\u001b[39;49mfields,\n\u001b[1;32m   1395\u001b[0m     )\n\u001b[1;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mshape:\n\u001b[1;32m   1397\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/zarr/core.py:2228\u001b[0m, in \u001b[0;36mArray._chunk_getitems\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[39mfor\u001b[39;00m ckey, chunk_select, out_select \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ckeys, lchunk_selection, lout_selection):\n\u001b[1;32m   2227\u001b[0m     \u001b[39mif\u001b[39;00m ckey \u001b[39min\u001b[39;00m cdatas:\n\u001b[0;32m-> 2228\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_chunk(\n\u001b[1;32m   2229\u001b[0m             out,\n\u001b[1;32m   2230\u001b[0m             cdatas[ckey],\n\u001b[1;32m   2231\u001b[0m             chunk_select,\n\u001b[1;32m   2232\u001b[0m             drop_axes,\n\u001b[1;32m   2233\u001b[0m             out_is_ndarray,\n\u001b[1;32m   2234\u001b[0m             fields,\n\u001b[1;32m   2235\u001b[0m             out_select,\n\u001b[1;32m   2236\u001b[0m             partial_read_decode\u001b[39m=\u001b[39;49mpartial_read_decode,\n\u001b[1;32m   2237\u001b[0m         )\n\u001b[1;32m   2238\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2239\u001b[0m         \u001b[39m# check exception type\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/zarr/core.py:2141\u001b[0m, in \u001b[0;36mArray._process_chunk\u001b[0;34m(self, out, cdata, chunk_selection, drop_axes, out_is_ndarray, fields, out_selection, partial_read_decode)\u001b[0m\n\u001b[1;32m   2139\u001b[0m \u001b[39mexcept\u001b[39;00m ArrayIndexError:\n\u001b[1;32m   2140\u001b[0m     cdata \u001b[39m=\u001b[39m cdata\u001b[39m.\u001b[39mread_full()\n\u001b[0;32m-> 2141\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode_chunk(cdata)\n\u001b[1;32m   2143\u001b[0m \u001b[39m# select data from chunk\u001b[39;00m\n\u001b[1;32m   2144\u001b[0m \u001b[39mif\u001b[39;00m fields:\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/zarr/core.py:2402\u001b[0m, in \u001b[0;36mArray._decode_chunk\u001b[0;34m(self, cdata, start, nitems, expected_shape)\u001b[0m\n\u001b[1;32m   2400\u001b[0m         chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compressor\u001b[39m.\u001b[39mdecode_partial(cdata, start, nitems)\n\u001b[1;32m   2401\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2402\u001b[0m         chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compressor\u001b[39m.\u001b[39;49mdecode(cdata)\n\u001b[1;32m   2403\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2404\u001b[0m     chunk \u001b[39m=\u001b[39m cdata\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/site-packages/numcodecs/gzip.py:54\u001b[0m, in \u001b[0;36mGZip.decode\u001b[0;34m(self, buf, out)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnable to fit data into `out`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m         out \u001b[39m=\u001b[39m decompressor\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/_compression.py:118\u001b[0m, in \u001b[0;36mDecompressReader.readall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m chunks \u001b[39m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m \u001b[39m# sys.maxsize means the max length of output buffer is unlimited,\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# so that the whole input buffer can be decompressed within one\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# .decompress() call.\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[39mwhile\u001b[39;00m data \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(sys\u001b[39m.\u001b[39;49mmaxsize):\n\u001b[1;32m    119\u001b[0m     chunks\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m~/miniconda3/envs/lsd_new/lib/python3.10/gzip.py:496\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39m# Read a chunk of data from the file\u001b[39;00m\n\u001b[1;32m    494\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m--> 496\u001b[0m uncompress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(buf, size)\n\u001b[1;32m    497\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    498\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mprepend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def find_max_value(zarr_array):\n",
    "  max_value = 0  # Initialize max_value to 0 (assuming all values are non-negative)\n",
    "  total_layers = zarr_array.shape[0]\n",
    "\n",
    "  for layer_index in range(total_layers):\n",
    "    layer = zarr_array[layer_index, :, :]\n",
    "    layer_max = layer.max()\n",
    "    if layer_max > max_value:\n",
    "      max_value = layer_max\n",
    "    print(f\"Layer index: {layer_index}, Current max value: {max_value}\")\n",
    "\n",
    "  return max_value\n",
    "\n",
    "data = zarr.open('3M-APP-SCN.zarr', mode='r')\n",
    "zarr_array = data['segmentation_0.1']\n",
    "\n",
    "max_value = find_max_value(zarr_array)\n",
    "print(f\"The maximum value in the entire array is: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "def filter_layers(args):\n",
    "    start_layer, end_layer, zarr_array, ids_to_remove = args\n",
    "    modified_layers = []\n",
    "    for layer_idx in range(start_layer, end_layer):\n",
    "        layer = zarr_array[layer_idx, :, :]\n",
    "        modified_layer = np.where(np.isin(layer, list(ids_to_remove)), 0, layer)\n",
    "        modified_layers.append(modified_layer)\n",
    "    return modified_layers\n",
    "\n",
    "def parallel_filter(zarr_array, ids_to_remove, num_cores):\n",
    "    total_layers = zarr_array.shape[0]\n",
    "    layers_per_core = total_layers // num_cores\n",
    "    remainder = total_layers % num_cores\n",
    "\n",
    "    args = []\n",
    "    start_layer = 0\n",
    "    for i in range(num_cores):\n",
    "        end_layer = start_layer + layers_per_core\n",
    "        if i < remainder:\n",
    "            end_layer += 1  # give one extra layer to this core\n",
    "        args.append((start_layer, end_layer, zarr_array, ids_to_remove))\n",
    "        start_layer = end_layer\n",
    "\n",
    "    with Pool(num_cores) as pool:\n",
    "        results = pool.map(filter_layers, args)\n",
    "\n",
    "    # Combine results\n",
    "    modified_segmentation = np.vstack(results)\n",
    "    return modified_segmentation\n",
    "\n",
    "# Your main code here\n",
    "threshold = 5\n",
    "ids_to_remove = set(seg_id for seg_id, count in segmentation_counts.items() if count < threshold)\n",
    "\n",
    "num_cores = min(cpu_count(), 16)  # Use up to 16 cores\n",
    "modified_segmentation = parallel_filter(zarr_array, ids_to_remove, num_cores)\n",
    "\n",
    "# Create a new Zarr file\n",
    "filtered_zarr = zarr.open('8M-APP-retina-100M_filtered.zarr', mode='w')\n",
    "\n",
    "# Save the raw dataset\n",
    "filtered_zarr['raw'] = np.transpose(data['raw'], (2, 1, 0))\n",
    "filtered_zarr['segmentation_0.1'] = np.transpose(modified_segmentation, (2, 1, 0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsd_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
